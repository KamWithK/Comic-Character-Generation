{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys; sys.path.append(\"../src\")\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import trange\n",
    "from models.gan_trainer import GANTrainer\n",
    "from models.custom_generator import Generator\n",
    "from models.custom_discriminator import Discriminator\n",
    "from models.resnet_discriminator import ResnetDiscriminator\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.image_dataset import ImageDataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-portable",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "judicial-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SIZE, CHANNELS = 64, 3\n",
    "NOISE_SIZE, LATENT_DIMS = 1, 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPOCHS = 300\n",
    "MAX_IMAGES, LOG_IMAGES_EVERY = None, 200\n",
    "GENERATOR_HIDDEN_DIMS = [800, 400, 200, 100, CHANNELS]\n",
    "DISCRIMINATOR_HIDDEN_DIMS = [64, 128, 256, 512, NOISE_SIZE]\n",
    "\n",
    "GENERATOR_LR, DISCRIMINATOR_LR = 0.0002, 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-thousand",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kamwithk (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Abstract Art 64 Standard Test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kamwithk/gan-demo\" target=\"_blank\">https://wandb.ai/kamwithk/gan-demo</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kamwithk/gan-demo/runs/1f3zetq4\" target=\"_blank\">https://wandb.ai/kamwithk/gan-demo/runs/1f3zetq4</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\kamwi\\Development\\LionelPolanski\\notebooks\\wandb\\run-20210521_121105-1f3zetq4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1f3zetq4)</h1><iframe src=\"https://wandb.ai/kamwithk/gan-demo/runs/1f3zetq4\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1bc4e011108>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"gan-demo\", name=f\"Abstract Art {SIZE} Standard Test\", mode=\"online\")\n",
    "# wandb.init(project=\"comic-character-generation\", entity=\"lionel-polanski\", name=f\"RaGAN {SIZE} PDSH\", dir=\"..\", mode=\"online\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-drinking",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beginning-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # ImageNet values\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\"../data/cleaned\", MAX_IMAGES, transform, NOISE_SIZE, LATENT_DIMS)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-brother",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shared-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vertical-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(LATENT_DIMS, GENERATOR_HIDDEN_DIMS).to(DEVICE)\n",
    "discriminator = Discriminator(CHANNELS, DISCRIMINATOR_HIDDEN_DIMS).to(DEVICE)\n",
    "# discriminator = ResnetDiscriminator(models.resnet18(pretrained=False), SIZE).to(DEVICE)\n",
    "\n",
    "generator = generator.apply(weights_init)\n",
    "discriminator = discriminator.apply(weights_init)\n",
    "\n",
    "wandb.watch(generator);\n",
    "wandb.watch(discriminator);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "presidential-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(128, 800, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(800, 400, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(400, 200, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(200, 100, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4): ConvTranspose2d(100, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 800, 4, 4]       1,639,200\n",
      "   ConvTranspose2d-2            [-1, 400, 8, 8]       5,120,000\n",
      "       BatchNorm2d-3            [-1, 400, 8, 8]             800\n",
      "              ReLU-4            [-1, 400, 8, 8]               0\n",
      "   ConvTranspose2d-5          [-1, 200, 16, 16]       1,280,000\n",
      "       BatchNorm2d-6          [-1, 200, 16, 16]             400\n",
      "              ReLU-7          [-1, 200, 16, 16]               0\n",
      "   ConvTranspose2d-8          [-1, 100, 32, 32]         320,000\n",
      "       BatchNorm2d-9          [-1, 100, 32, 32]             200\n",
      "             ReLU-10          [-1, 100, 32, 32]               0\n",
      "  ConvTranspose2d-11            [-1, 3, 64, 64]           4,800\n",
      "             Tanh-12            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 8,365,400\n",
      "Trainable params: 8,365,400\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.39\n",
      "Params size (MB): 31.91\n",
      "Estimated Total Size (MB): 36.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(generator, (LATENT_DIMS, NOISE_SIZE, NOISE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "injured-consortium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "radio-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           3,072\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "         LeakyReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-6          [-1, 128, 16, 16]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-8            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-9            [-1, 256, 8, 8]               0\n",
      "           Conv2d-10            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-11            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-12            [-1, 512, 4, 4]               0\n",
      "           Conv2d-13              [-1, 1, 1, 1]           8,192\n",
      "================================================================\n",
      "Total params: 2,765,696\n",
      "Trainable params: 2,765,696\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.81\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 13.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(discriminator, (CHANNELS, SIZE, SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-tonight",
   "metadata": {},
   "source": [
    "## Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tracked-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimiser = optim.Adam(generator.parameters(), lr=GENERATOR_LR, betas=(0.5, 0.999))\n",
    "discriminator_optimiser = optim.Adam(discriminator.parameters(), lr=DISCRIMINATOR_LR, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thermal-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_trainer = GANTrainer(generator, discriminator, generator_optimiser, discriminator_optimiser, relavistic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-innocent",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "equivalent-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "denormalise = transforms.Compose([\n",
    "  transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "  transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.])\n",
    "])\n",
    "\n",
    "generations = lambda num_samples : denormalise(gan_trainer.generator(torch.randn(num_samples, *dataset[0][0].shape, device=DEVICE)))\n",
    "wandb_images = lambda images : {\"generations\": [wandb.Image(image) for image in images]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(EPOCHS):\n",
    "    for index, (noise, imgs) in enumerate(dataloader):\n",
    "        # Labels\n",
    "        real_label = torch.full((imgs.size(0),), 1., dtype=torch.float, device=DEVICE)\n",
    "        fake_label = torch.full((imgs.size(0),), 0., dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "        noise, imgs = noise.to(DEVICE), imgs.to(DEVICE)\n",
    "        \n",
    "        real_loss, fake_loss = gan_trainer.train_discriminator(noise, imgs, real_label, fake_label)\n",
    "        generator_loss = gan_trainer.train_generator(noise, imgs, real_label, fake_label)\n",
    "        \n",
    "        # Log Stats\n",
    "        wandb.log({\n",
    "            \"real_loss\": real_loss, \"fake_loss\": fake_loss,\n",
    "            \"generator_loss\": generator_loss\n",
    "        })\n",
    "        \n",
    "        # LOG SAMPLE IMAGES AFTER LOG_IMAGES_EVERY STEPS\n",
    "        if index % LOG_IMAGES_EVERY == 0: wandb.log(wandb_images(generations(5)))\n",
    "        \n",
    "    # LOG SAMPLE IMAGES AFTER EACH EPOCH\n",
    "    wandb.log(wandb_images(generations(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), os.path.join(wandb.run.dir, \"generator_model.pt\"))\n",
    "torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, \"discriminator_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-sound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
